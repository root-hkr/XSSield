{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XSSClassifier:  XSS Attack Detection Approach Based on Machine Learning Classifier in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gather Test Data \n",
    "Get a list of samples and create an array with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\hkrdh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (6.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\hkrdh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.23.0)\n",
      "Requirement already satisfied: Levenshtein==0.23.0 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-Levenshtein) (0.23.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Levenshtein==0.23.0->python-Levenshtein) (3.5.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\hkrdh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\hkrdh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\hkrdh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hkrdh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hkrdh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Data...\n",
      "****"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U numpy\n",
    "!{sys.executable} -m pip install -U gensim\n",
    "!{sys.executable} -m pip install -U python-Levenshtein\n",
    "!{sys.executable} -m pip install -U nltk\n",
    "!{sys.executable} -m pip install -U scikit-learn\n",
    "\n",
    "# Importing necessary libraries\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy import *\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import urllib.parse as url_parse\n",
    "import pickle\n",
    "\n",
    "# Initialize lists for XSS and normal data\n",
    "xss_data = []\n",
    "normal_data = []\n",
    "X_temp = []\n",
    "X = []\n",
    "y = []\n",
    "xss_count = 0\n",
    "normal_count = 0\n",
    "\n",
    "print(\"Fetching Data...\")\n",
    "\n",
    "# Load XSS strings and label them as 1 in the y array\n",
    "with open('lib/xss_samples.txt', 'r') as f:\n",
    "    xss_data = f.readlines()\n",
    "print(\"*\", sep=' ', end='', flush=True)\n",
    "\n",
    "# Extract the query part of the URL and filter out potential open redirect vulnerabilities\n",
    "for line in xss_data:\n",
    "    query = url_parse.urlsplit(line)[3]\n",
    "    if \"?http\" in str(line) or \"?url=http\" in str(line) or \"?fwd=http\" in str(line) or \"?path=http\" in str(line) or \"=http\" in str(query) or \"page=search\" in str(query):\n",
    "        continue\n",
    "    if len(query) > 8:\n",
    "        xss_count += 1\n",
    "        X_temp.append(line)\n",
    "\n",
    "# Remove duplicates\n",
    "deduplicated_xss = list(dict.fromkeys(X_temp))\n",
    "print(\"*\", sep=' ', end='', flush=True)\n",
    "\n",
    "# Add features to X and labels to the y array for XSS data\n",
    "for line in deduplicated_xss:\n",
    "    X.append(line)\n",
    "    y.append(1)\n",
    "\n",
    "X_temp = []\n",
    "deduplicated_xss = []\n",
    "print(\"*\", sep=' ', end='', flush=True)\n",
    "\n",
    "# Load normal strings and label them as 0 in the y array\n",
    "with open('lib/normal_samples.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    normal_data = f.readlines()\n",
    "\n",
    "# Extract the query part of the URL\n",
    "for line in normal_data:\n",
    "    query = url_parse.urlsplit(line)[3]\n",
    "    if len(query) > 3:\n",
    "        normal_count += 1\n",
    "        X_temp.append(line)\n",
    "\n",
    "# Remove duplicates\n",
    "deduplicated_normal = list(dict.fromkeys(X_temp))\n",
    "print(\"*\", sep=' ', end='', flush=True)\n",
    "\n",
    "# Add features to X and labels to the y array for normal data\n",
    "for line in deduplicated_normal:\n",
    "    X.append(line)\n",
    "    y.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of XSS Samples: 38608\n",
      "Number of NOT XSS Samples: 44826\n",
      "Total Samples: 83434\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of XSS Samples: \"+str(xss_count))\n",
    "print(\"Number of NOT XSS Samples: \"+str(normal_count))\n",
    "print(\"Total Samples: \"+str(xss_count+normal_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an array of the features for each test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the sample vector model...\n",
      "*******"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m X_features \u001b[38;5;241m=\u001b[39m \u001b[43mgenerateFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mgenerateFeatures\u001b[1;34m(text_data)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtagged_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0002\u001b[39m\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mmin_alpha \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39malpha\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets\n\u001b[0;32m    514\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_doctags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_doctags\n\u001b[1;32m--> 516\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\word2vec.py:1073\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1073\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1078\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_corpusfile(\n\u001b[0;32m   1079\u001b[0m         corpus_file, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[0;32m   1080\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\word2vec.py:1434\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m-> 1434\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\word2vec.py:1289\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m   1286\u001b[0m unfinished_worker_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1289\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mprogress_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m         unfinished_worker_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a function to convert an array of query strings to a set of features\n",
    "def generateFeatures(text_data):\n",
    "    tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(text_data)]\n",
    "    max_epochs = 25\n",
    "    vec_size = 20\n",
    "    alpha = 0.025\n",
    "\n",
    "    model = Doc2Vec(vector_size=vec_size,\n",
    "                    alpha=alpha,\n",
    "                    min_alpha=0.00025,\n",
    "                    min_count=1,\n",
    "                    dm=1)\n",
    "    model.build_vocab(tagged_data)\n",
    "    print(\"Building the sample vector model...\")\n",
    "    features = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"*\", sep=' ', end='', flush=True)\n",
    "        model.random.seed(42)\n",
    "        model.train(tagged_data,\n",
    "                    total_examples=model.corpus_count,\n",
    "                    epochs=model.epochs)\n",
    "        model.alpha -= 0.0002\n",
    "        model.min_alpha = model.alpha\n",
    "\n",
    "    model.save(\"lib/d2v_model\")\n",
    "    print()\n",
    "    print(\"Model Saved\")\n",
    "\n",
    "    for i, line in enumerate(text_data):\n",
    "        feature_vec = [model.dv[i]]\n",
    "        line_decoded = unquote(line)\n",
    "        line_decoded = line_decoded.replace(\" \", \"\")\n",
    "        lower_str = str(line_decoded).lower()\n",
    "\n",
    "        # Feature extraction\n",
    "        feature1 = int(lower_str.count('<link')) + int(lower_str.count('<object')) + int(lower_str.count('<form'))\n",
    "        # Add more features here...\n",
    "\n",
    "        feature_vec = np.append(feature_vec, feature1)\n",
    "        # Add more features here...\n",
    "\n",
    "        features.append(feature_vec)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Example usage\n",
    "X_features = generateFeatures(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = generateFeatures(X)\n",
    "features_dict = {'data':X,'features':features,'label':y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sample: http://search.rin.ru/cgi-bin/find.cgi?text=%3Cscript%3Ealert(%27HZ+iz+1337%27)%3B%3C%2Fscript%3E\n",
      "\n",
      "Features: [ 1.70212924 -1.82771647  2.17515659  2.02932262 -0.75966585 -1.18975067\n",
      " -0.71887583  0.25190741  1.54317236 -1.36383951  2.34889245  0.26069176\n",
      "  2.36285257 -0.36768007  1.09289861  1.08891952 -1.69099092  3.48596787\n",
      " -1.11877799 -1.52294385  0.          0.          0.         81.\n",
      "  1.         15.        ]\n",
      "\n",
      "Label:\u001b[1;31;1m XSS(1)/\u001b[1;32;1m NOT XSS(0)\u001b[0;0m: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Sample: \"+ X[0])\n",
    "print(\"Features: \" + str(features[0]))\n",
    "print(\"\\nLabel:\\033[1;31;1m XSS(1)/\\033[1;32;1m NOT XSS(0)\\033[0;0m: \" + str(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "Train/Test split the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size = .3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(random_state=42)\n",
      "\n",
      "SVC(kernel='linear', random_state=42)\n",
      "\n",
      "GaussianNB()\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=25)\n",
      "\n",
      "RandomForestClassifier(random_state=42)\n",
      "\n",
      "MLPClassifier(max_iter=2000, random_state=42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use RandomState for reproducibility.\n",
    "from sklearn import tree\n",
    "my_classifier1 = tree.DecisionTreeClassifier(random_state=42)\n",
    "print(my_classifier1)\n",
    "print()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "my_classifier2 = SVC(kernel='linear', random_state=42)\n",
    "print(my_classifier2)\n",
    "print()\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "my_classifier3 = GaussianNB()\n",
    "print(my_classifier3)\n",
    "print()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "my_classifier4 = KNeighborsClassifier(n_neighbors=25, weights='uniform')\n",
    "print(my_classifier4)\n",
    "print()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "my_classifier5 = RandomForestClassifier(random_state=42)\n",
    "print(my_classifier5)\n",
    "print()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "my_classifier6 = MLPClassifier(max_iter=2000, random_state=42)\n",
    "print(my_classifier6)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additonal tunning of hyperparameters can be done.\n",
    "\n",
    "I have only set the KNN n_neighbors weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier #1 DecisionTreeClassifier\n",
      "Training Classifier #2 SVC\n",
      "Training Classifier #3 GaussianNB\n",
      "Training Classifier #4 KNeighborsClassifier\n",
      "Training Classifier #5 RandomForestClassifier\n",
      "Training Classifier #6 MLPClassifier\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Classifier #1 DecisionTreeClassifier\")\n",
    "my_classifier1.fit(X_train, y_train)\n",
    "print(\"Training Classifier #2 SVC\")\n",
    "my_classifier2.fit(X_train, y_train)\n",
    "print(\"Training Classifier #3 GaussianNB\")\n",
    "my_classifier3.fit(X_train, y_train)\n",
    "print(\"Training Classifier #4 KNeighborsClassifier\")\n",
    "my_classifier4.fit(X_train, y_train)\n",
    "print(\"Training Classifier #5 RandomForestClassifier\")\n",
    "my_classifier5.fit(X_train, y_train)\n",
    "print(\"Training Classifier #6 MLPClassifier\")\n",
    "my_classifier6.fit(X_train, y_train)\n",
    "\n",
    "predictions1 = my_classifier1.predict(X_test)\n",
    "predictions2 = my_classifier2.predict(X_test)\n",
    "predictions3 = my_classifier3.predict(X_test)\n",
    "predictions4 = my_classifier4.predict(X_test)\n",
    "predictions5 = my_classifier5.predict(X_test)\n",
    "predictions6 = my_classifier6.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score #1: 98.5%\n",
      "Accuracy Score #2: 98.4%\n",
      "Accuracy Score #3: 94.9%\n",
      "Accuracy Score #4: 96.2%\n",
      "Accuracy Score #5: 99.5%\n",
      "Accuracy Score #6: 99.6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score #1: {:.1%}'.format(accuracy_score(y_test, predictions1)))\n",
    "print('Accuracy Score #2: {:.1%}'.format(accuracy_score(y_test, predictions2)))\n",
    "print('Accuracy Score #3: {:.1%}'.format(accuracy_score(y_test, predictions3)))\n",
    "print('Accuracy Score #4: {:.1%}'.format(accuracy_score(y_test, predictions4)))\n",
    "print('Accuracy Score #5: {:.1%}'.format(accuracy_score(y_test, predictions5)))\n",
    "print('Accuracy Score #6: {:.1%}'.format(accuracy_score(y_test, predictions6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report #1 DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     13437\n",
      "           1       0.98      0.98      0.98     11594\n",
      "\n",
      "    accuracy                           0.98     25031\n",
      "   macro avg       0.98      0.98      0.98     25031\n",
      "weighted avg       0.98      0.98      0.98     25031\n",
      "\n",
      "Classification Report #2 SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     13437\n",
      "           1       0.99      0.97      0.98     11594\n",
      "\n",
      "    accuracy                           0.98     25031\n",
      "   macro avg       0.98      0.98      0.98     25031\n",
      "weighted avg       0.98      0.98      0.98     25031\n",
      "\n",
      "Classification Report #3 GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95     13437\n",
      "           1       0.94      0.95      0.95     11594\n",
      "\n",
      "    accuracy                           0.95     25031\n",
      "   macro avg       0.95      0.95      0.95     25031\n",
      "weighted avg       0.95      0.95      0.95     25031\n",
      "\n",
      "Classification Report #4 KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     13437\n",
      "           1       0.98      0.93      0.96     11594\n",
      "\n",
      "    accuracy                           0.96     25031\n",
      "   macro avg       0.96      0.96      0.96     25031\n",
      "weighted avg       0.96      0.96      0.96     25031\n",
      "\n",
      "Classification Report #5 RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     13437\n",
      "           1       1.00      0.99      0.99     11594\n",
      "\n",
      "    accuracy                           0.99     25031\n",
      "   macro avg       1.00      0.99      0.99     25031\n",
      "weighted avg       0.99      0.99      0.99     25031\n",
      "\n",
      "Classification Report #6 MLPClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     13437\n",
      "           1       1.00      0.99      1.00     11594\n",
      "\n",
      "    accuracy                           1.00     25031\n",
      "   macro avg       1.00      1.00      1.00     25031\n",
      "weighted avg       1.00      1.00      1.00     25031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report #1 DecisionTreeClassifier\")\n",
    "print(classification_report(y_test, predictions1))\n",
    "print(\"Classification Report #2 SVC\")\n",
    "print(classification_report(y_test, predictions2))\n",
    "print(\"Classification Report #3 GaussianNB\")\n",
    "print(classification_report(y_test, predictions3))\n",
    "print(\"Classification Report #4 KNeighborsClassifier\")\n",
    "print(classification_report(y_test, predictions4))\n",
    "print(\"Classification Report #5 RandomForestClassifier\")\n",
    "print(classification_report(y_test, predictions5))\n",
    "print(\"Classification Report #6 MLPClassifier\")\n",
    "print(classification_report(y_test, predictions6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix #1 DecisionTreeClassifier\n",
      "[[13249   188]\n",
      " [  192 11402]]\n",
      "\n",
      "Confusion Matrix #2 SVC\n",
      "[[13344    93]\n",
      " [  305 11289]]\n",
      "\n",
      "Confusion Matrix #3 GaussianNB\n",
      "[[12690   747]\n",
      " [  533 11061]]\n",
      "\n",
      "Confusion Matrix #4 KNeighborsClassifier\n",
      "[[13269   168]\n",
      " [  780 10814]]\n",
      "\n",
      "Confusion Matrix #5 RandomForestClassifier\n",
      "[[13419    18]\n",
      " [  110 11484]]\n",
      "\n",
      "Confusion Matrix #6 MLPClassifier\n",
      "[[13411    26]\n",
      " [   86 11508]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nConfusion Matrix #1 DecisionTreeClassifier\")\n",
    "print(confusion_matrix(y_test, predictions1))\n",
    "print(\"\\nConfusion Matrix #2 SVC\")\n",
    "print(confusion_matrix(y_test, predictions2))\n",
    "print(\"\\nConfusion Matrix #3 GaussianNB\")\n",
    "print(confusion_matrix(y_test, predictions3))\n",
    "print(\"\\nConfusion Matrix #4 KNeighborsClassifier\")\n",
    "print(confusion_matrix(y_test, predictions4))\n",
    "print(\"\\nConfusion Matrix #5 RandomForestClassifier\")\n",
    "print(confusion_matrix(y_test, predictions5))\n",
    "print(\"\\nConfusion Matrix #6 MLPClassifier\")\n",
    "print(confusion_matrix(y_test, predictions6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier #1 DecisionTreeClassifier\n",
      "Training Classifier #2 SVC\n",
      "Training Classifier #3 GaussianNB\n",
      "Training Classifier #4 KNeighborsClassifier\n",
      "Training Classifier #5 RandomForestClassifier\n",
      "Training Classifier #6 MLPClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(max_iter=2000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=2000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(max_iter=2000, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Classifier #1 DecisionTreeClassifier\")\n",
    "my_classifier1.fit(features, y)\n",
    "\n",
    "print(\"Training Classifier #2 SVC\")\n",
    "my_classifier2.fit(features, y)\n",
    "\n",
    "print(\"Training Classifier #3 GaussianNB\")\n",
    "my_classifier3.fit(features, y)\n",
    "\n",
    "print(\"Training Classifier #4 KNeighborsClassifier\")\n",
    "my_classifier4.fit(features, y)\n",
    "\n",
    "print(\"Training Classifier #5 RandomForestClassifier\")\n",
    "my_classifier5.fit(features, y)\n",
    "\n",
    "print(\"Training Classifier #6 MLPClassifier\")\n",
    "my_classifier6.fit(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename1 = 'lib/DecisionTreeClassifier.sav'\n",
    "pickle.dump(my_classifier1, open(filename1, 'wb'))\n",
    "\n",
    "filename2 = 'lib/SVC.sav'\n",
    "pickle.dump(my_classifier2, open(filename2, 'wb'))\n",
    "\n",
    "filename3 = 'lib/GaussianNB.sav'\n",
    "pickle.dump(my_classifier3, open(filename3, 'wb'))\n",
    "\n",
    "filename4 = 'lib/KNeighborsClassifier.sav'\n",
    "pickle.dump(my_classifier4, open(filename4, 'wb'))\n",
    "\n",
    "filename5 = 'lib/RandomForestClassifier.sav'\n",
    "pickle.dump(my_classifier5, open(filename5, 'wb'))\n",
    "\n",
    "filename6 = 'lib/MLPClassifier.sav'\n",
    "pickle.dump(my_classifier6, open(filename6, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model1 = pickle.load(open(filename1, 'rb'))\n",
    "loaded_model2 = pickle.load(open(filename2, 'rb'))\n",
    "loaded_model3 = pickle.load(open(filename3, 'rb'))\n",
    "loaded_model4 = pickle.load(open(filename4, 'rb'))\n",
    "loaded_model5 = pickle.load(open(filename5, 'rb'))\n",
    "loaded_model6 = pickle.load(open(filename6, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testXSS = [\n",
    "                '<script>alert(\\'xss\\')</script><script><script>',\n",
    "                'hellomo',\n",
    "                'https://store.bentley.com/en/shop/search?term=%22%3E%3Cdetails%20open%20ontoggle=prompt(1337)%3ExxLouisLouisLouis',\n",
    "                'ghfdhgdhjgd',\n",
    "                'uid%3D19%26list_page%3D%22%3E%3Cscript%3Ealert%28document.cookie%29%3B%3C/script%3E',\n",
    "                '&template=en_search_error&postalCode=\\\\\\';alert(0)//',\n",
    "                '&where=%3Cscript%3Ealert%28%27xss%27%29%3C%2Fscript%3E&loctypes=1003%2C1001%2C1000%2C1%2C9%2C5%2C11%2C13%2C19%2C20&from=hdr_localsearch',\n",
    "                'http://mydata.com/sad/sd/qwd/qwde/qwe/?sessionid=12',\n",
    "                'http://mydata.com?id=script',\n",
    "                '&\\';}},{scope:\\'email,user_about_me,user_hometown,user_interests,user_likes,user_status,user_website,user_birthday,publish_stream,publish_actions,offline_access\\'});}alert(0);b=function(response){c=({a:{//',\n",
    "                'http://myurl.com?<script',\n",
    "                'http://mydata.com?script=script',\n",
    "                'composite_search=1&keyword=\"/><script>alert(\"Xss:Vijayendra\")</script>',\n",
    "                'http://mysite.com?srtalert',\n",
    "                'script',\n",
    "                'alert',\n",
    "                'Search=%22%3E\\'%3E%3CSCRIPT%20SRC=http://br.zone-h.org/testes/xss.js%3E%3C/SCRIPT%3E?',\n",
    "                'id=15%3Cscript%3Ealert%28document.cookie%29%3C/script%3E',\n",
    "                'composite_search=1&keyword=\"/><script>alert(\"Xss:Vijayendra\")</script>',\n",
    "                'id=123&href=abdc<a<script>alert(1)',\n",
    "                '<<<<<<>>>>></>,><><>',\n",
    "                'alert()alert()',\n",
    "                'alertalert',\n",
    "                '?url=http://localhost:8888/notebooks/Documents/MachineLearning/Practical%20Machine%20Learning',\n",
    "                '<script<script',\n",
    "                '<scriptalert',\n",
    "                'httphttphttp',\n",
    "                'https://disqus.com/?ref_noscript',\n",
    "                'I am a string',\n",
    "                '<img src=\"javascript:alert(1)/>\"',\n",
    "                'HelloWorld!',\n",
    "                'http://mysite.com?<script>',\n",
    "                '<input type=\"text\" value=`` <div/onmouseover=\\'alert(471)\\'>X</div>',\n",
    "                '<img \\x47src=x onerror=\"javascript:alert(324)\">',\n",
    "                '<a href=\"\\xE2\\x80\\x87javascript:javascript:alert(183)\" id=\"fuzzelement1\">test</a>',\n",
    "                '<body onscroll=javascript:alert(288)><br><br><br><br><br><br>...<br><br><br><br><br><br><br><br><br><br>...<br><br><br><br><br><br><br><br><br><br>...<br><br><br><br><br><br><br><br><br><br>...<br><br><br><br><br><br><br><br><br><br>...<br><br><br><br><input autofocus>',\n",
    "                '<meta charset=\"mac-farsi\">¼script¾javascript:alert(379)¼/script¾',\n",
    "                '<HTML xmlns:xss><?import namespace=(493)s\" implementation=\"%(htc)s\"><xss:xss>XSS</xss:xss></HTML>\"\"\",\"XML namespace.\"),(\"\"\"<XML ID=(494)s\"><I><B>&lt;IMG SRC=\"javas<!-- -->cript:javascript:alert(420)\"&gt;</B></I></XML><SPAN DATASRC=\"#xss\" DATAFLD=\"B\" DATAFORMATAS=\"HTML\"></SPAN>'\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "#print(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the sample vector model...\n",
      "*************************\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "Xnew = getVec(testXSS)\n",
    "# make a prediction\n",
    "#1 DecisionTreeClassifier\n",
    "ynew1 = loaded_model1.predict(Xnew)\n",
    "#2 SVC\n",
    "ynew2 = loaded_model2.predict(Xnew)\n",
    "#3 GaussianNB\n",
    "ynew3 = loaded_model3.predict(Xnew)\n",
    "#4 KNeighborsClassifier\n",
    "ynew4 = loaded_model4.predict(Xnew)\n",
    "#5 RandomForestClassifier\n",
    "ynew5 = loaded_model5.predict(Xnew)\n",
    "#6 MLPClassifier\n",
    "ynew6 = loaded_model6.predict(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <script>alert('xss')</script><script><script>\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.175\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => hellomo\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0.625\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => https://store.bentley.com/en/shop/search?term=%22%3E%3Cdetails%20open%20ontoggle=prompt(1337)%3ExxLouisLouisLouis\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => ghfdhgdhjgd\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => uid%3D19%26list_page%3D%22%3E%3Cscript%3Ealert%28document.cookie%29%3B%3C/script%3E\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => &template=en_search_error&postalCode=\\';alert(0)//\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => &where=%3Cscript%3Ealert%28%27xss%27%29%3C%2Fscript%3E&loctypes=1003%2C1001%2C1000%2C1%2C9%2C5%2C11%2C13%2C19%2C20&from=hdr_localsearch\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0.475\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => http://mydata.com/sad/sd/qwd/qwde/qwe/?sessionid=12\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => http://mydata.com?id=script\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0.22499999999999998\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => &';}},{scope:'email,user_about_me,user_hometown,user_interests,user_likes,user_status,user_website,user_birthday,publish_stream,publish_actions,offline_access'});}alert(0);b=function(response){c=({a:{//\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => http://myurl.com?<script\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => http://mydata.com?script=script\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => composite_search=1&keyword=\"/><script>alert(\"Xss:Vijayendra\")</script>\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => http://mysite.com?srtalert\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => script\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => alert\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => Search=%22%3E'%3E%3CSCRIPT%20SRC=http://br.zone-h.org/testes/xss.js%3E%3C/SCRIPT%3E?\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => id=15%3Cscript%3Ealert%28document.cookie%29%3C/script%3E\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => composite_search=1&keyword=\"/><script>alert(\"Xss:Vijayendra\")</script>\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => id=123&href=abdc<a<script>alert(1)\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0.44999999999999996\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => <<<<<<>>>>></>,><><>\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => alert()alert()\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => alertalert\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.175\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => ?url=http://localhost:8888/notebooks/Documents/MachineLearning/Practical%20Machine%20Learning\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <script<script\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <scriptalert\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => httphttphttp\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => https://disqus.com/?ref_noscript\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.0\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => I am a string\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <img src=\"javascript:alert(1)/>\"\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.175\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => HelloWorld!\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => http://mysite.com?<script>\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <input type=\"text\" value=`` <div/onmouseover='alert(471)'>X</div>\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <img Gsrc=x onerror=\"javascript:alert(324)\">\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <a href=\"âjavascript:javascript:alert(183)\" id=\"fuzzelement1\">test</a>\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <body onscroll=javascript:alert(288)><br><br><br><br><br><br>...<br><br><br><br><br><br><br><br><br><br>...<br><br><br><br><br><br><br><br><br><br>...<br><br><br><br><br><br><br><br><br><br>...<br><br><br><br><br><br><br><br><br><br>...<br><br><br><br><input autofocus>\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0.925\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <meta charset=\"mac-farsi\">¼script¾javascript:alert(379)¼/script¾\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => <HTML xmlns:xss><?import namespace=(493)s\" implementation=\"%(htc)s\"><xss:xss>XSS</xss:xss></HTML>\"\"\",\"XML namespace.\"),(\"\"\"<XML ID=(494)s\"><I><B>&lt;IMG SRC=\"javas<!-- -->cript:javascript:alert(420)\"&gt;</B></I></XML><SPAN DATASRC=\"#xss\" DATAFLD=\"B\" DATAFORMATAS=\"HTML\"></SPAN>\n",
      "\n",
      "*------------- RESULTS -------------*\n",
      "\u001b[1;31;1mXSS\u001b[0;0m => 20\n",
      "\u001b[1;32;1mNOT XSS\u001b[0;0m => 18\n"
     ]
    }
   ],
   "source": [
    "# show the sample inputs and predicted outputs using a wighted value\n",
    "xssCount = 0 \n",
    "notXssCount = 0\n",
    "for i in range(len(Xnew)):\n",
    "    score = ((.175*ynew1[i])+(.15*ynew2[i])+(.05*ynew3[i])+(.075*ynew4[i])+(.25*ynew5[i])+(.3*ynew6[i]))\n",
    "    print(ynew1[i])\n",
    "    print(ynew2[i])\n",
    "    print(ynew3[i])\n",
    "    print(ynew4[i])\n",
    "    print(ynew5[i])\n",
    "    print(ynew6[i])\n",
    "    print(score)\n",
    "    if score >= .5:\n",
    "        print(\"\\033[1;31;1mXSS\\033[0;0m => \"+testXSS[i])\n",
    "        xssCount += 1\n",
    "    else:\n",
    "        print(\"\\033[1;32;1mNOT XSS\\033[0;0m => \"+testXSS[i])\n",
    "        notXssCount += 1\n",
    "\n",
    "print()\n",
    "print(\"*------------- RESULTS -------------*\")\n",
    "print(\"\\033[1;31;1mXSS\\033[0;0m => \"+str(xssCount))\n",
    "print(\"\\033[1;32;1mNOT XSS\\033[0;0m => \"+str(notXssCount))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
